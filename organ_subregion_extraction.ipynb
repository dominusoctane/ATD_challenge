{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac27e9b-a29b-4e4c-aea7-976bf6a1325d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "def collect_npy_data(base_directory):\n",
    "    \"\"\"\n",
    "    Traverse the directory structure and collect paths to .npy files.\n",
    "    \n",
    "    Args:\n",
    "    - base_directory (str): Root directory containing .npy files.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: Contains .npy file path, series_id, and numpy data for each .npy file.\n",
    "    \"\"\"\n",
    "    # List to collect data\n",
    "    npy_data = []\n",
    "\n",
    "    # Iterate through all files in the directory\n",
    "    for file_name in tqdm(os.listdir(base_directory), desc=\"Processing .npy files\"):\n",
    "        # Check if the current file is a .npy file\n",
    "        if file_name.endswith('.npy'):\n",
    "            series_id = int(file_name.split(\"_\")[0])  # Extracting series_id from the filename\n",
    "            file_path = os.path.join(base_directory, file_name)\n",
    "            \n",
    "            # Load numpy data\n",
    "            npy_array = np.load(file_path)\n",
    "            \n",
    "            # Append details to the list\n",
    "            npy_data.append({\n",
    "                'npy_path': file_path,\n",
    "                'series_id': series_id,\n",
    "                'npy_data': npy_array\n",
    "            })\n",
    "\n",
    "    # Convert the list into a DataFrame\n",
    "    npy_df = pd.DataFrame(npy_data)\n",
    "    \n",
    "    return npy_df\n",
    "\n",
    "# Example usage\n",
    "base_directory = 'volume_info'  # Replace with your directory path\n",
    "npy_df = collect_npy_data(base_directory)\n",
    "npy_df=npy_df.sort_values(by='series_id',axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4e55cd-1bd8-4ce3-8ca5-bf927a17a254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_last_indices(array, value):\n",
    "    \"\"\"\n",
    "    Get the first and last index of a value in a numpy array.\n",
    "\n",
    "    Args:\n",
    "    - array (numpy.ndarray): The input numpy array.\n",
    "    - value (int/float): The value to search for.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: (first index, last index) normalized by dividing by the total length of the array.\n",
    "    \"\"\"\n",
    "    indices = np.where(array == value)[0]\n",
    "    if indices.size == 0:\n",
    "        return [0, 0]\n",
    "    first_index = indices[0] / len(array)\n",
    "    last_index = indices[-1] / len(array)\n",
    "    return [first_index, last_index]\n",
    "\n",
    "def trim_zero_rows(matrix):\n",
    "    \"\"\"\n",
    "    Remove rows from the top and bottom of the matrix that contain only zeros.\n",
    "    Stop when a row with a non-zero entry is encountered from both directions.\n",
    "\n",
    "    Args:\n",
    "    - matrix (numpy.ndarray): 2D numpy array\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: Trimmed matrix\n",
    "    \"\"\"\n",
    "    # Find the index of the first row from the top that contains a non-zero entry\n",
    "    first_non_zero_row = np.argmax(np.any(matrix != 0, axis=1))\n",
    "    \n",
    "    # Find the index of the first row from the bottom that contains a non-zero entry\n",
    "    last_non_zero_row = matrix.shape[0] - 1 - np.argmax(np.any(matrix[::-1] != 0, axis=1))\n",
    "    \n",
    "    # Slice the matrix between these two rows\n",
    "    trimmed_matrix = matrix[first_non_zero_row:last_non_zero_row+1]\n",
    "    \n",
    "    return trimmed_matrix\n",
    "\n",
    "\n",
    "# ['liver', 'kidneys', 'spleen', 'bowel']\n",
    "\n",
    "liver_range_list = []\n",
    "kidneys_range_list = []\n",
    "spleen_range_list = []\n",
    "bowel_range_list = []\n",
    "\n",
    "bad_liver_indices = []\n",
    "bad_kidneys_indices = []\n",
    "bad_spleen_indices = []\n",
    "bad_bowel_indices = []\n",
    "\n",
    "series_depth_lengths = []\n",
    "\n",
    "for i in range(len(npy_df.npy_data)):\n",
    "    temp = npy_df.npy_data.iloc[i]\n",
    "    temp = trim_zero_rows(temp)\n",
    "\n",
    "    series_depth_lengths.append(len(temp[:,0]))\n",
    "    \n",
    "    liver_range = get_first_last_indices(temp[:,0], 1)\n",
    "    kidneys_range = get_first_last_indices(temp[:,1], 1)\n",
    "    spleen_range = get_first_last_indices(temp[:,2], 1)\n",
    "    bowel_range = get_first_last_indices(temp[:,3], 1)\n",
    "    \n",
    "    # Check if the range of each organ is (0,0) and append the index `i` to the corresponding list\n",
    "    if liver_range == [0,0]:\n",
    "        bad_liver_indices.append(i)\n",
    "    if kidneys_range == [0,0]:\n",
    "        bad_kidneys_indices.append(i)\n",
    "    if spleen_range == [0,0]:\n",
    "        bad_spleen_indices.append(i)\n",
    "    if bowel_range == [0,0]:\n",
    "        bad_bowel_indices.append(i)\n",
    "    \n",
    "    # Append the range values to the respective lists\n",
    "    liver_range_list.append(liver_range)\n",
    "    kidneys_range_list.append(kidneys_range)\n",
    "    spleen_range_list.append(spleen_range)\n",
    "    bowel_range_list.append(bowel_range)\n",
    "\n",
    "bad_cases = np.unique(bad_liver_indices + bad_kidneys_indices + bad_spleen_indices + bad_bowel_indices)\n",
    "\n",
    "liver_range_list = np.array(liver_range_list)\n",
    "kidneys_range_list = np.array(kidneys_range_list)\n",
    "spleen_range_list = np.array(spleen_range_list)\n",
    "bowel_range_list = np.array(bowel_range_list)\n",
    "\n",
    "mask = np.ones(liver_range_list.shape[0], dtype=bool)\n",
    "mask[bad_cases] = False\n",
    "\n",
    "original_liver_range_list = liver_range_list#[bad_cases, :]\n",
    "original_kidneys_range_list = kidneys_range_list#[bad_cases, :]\n",
    "original_spleen_range_list = spleen_range_list#[bad_cases, :]\n",
    "original_bowel_range_list = bowel_range_list#[bad_cases,:]\n",
    "\n",
    "liver_range_list = liver_range_list[mask, :]\n",
    "kidneys_range_list = kidneys_range_list[mask, :]\n",
    "spleen_range_list = spleen_range_list[mask, :]\n",
    "bowel_range_list = bowel_range_list[mask,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b2369e-e3cd-4ec6-a7c7-3bc38571fe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store the bad organs for each unique index\n",
    "bad_organs_dict = {}\n",
    "\n",
    "for idx in bad_cases:\n",
    "    is_bad_liver = int(idx in bad_liver_indices)\n",
    "    is_bad_kidneys = int(idx in bad_kidneys_indices)\n",
    "    is_bad_spleen = int(idx in bad_spleen_indices)\n",
    "    is_bad_bowel = int(idx in bad_bowel_indices)\n",
    "    \n",
    "    # Store the tuple (or list) for this index\n",
    "    bad_organs_dict[idx] = (is_bad_liver, is_bad_kidneys, is_bad_spleen, is_bad_bowel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db706384-8910-41b7-bb82-107a2e3bf93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def generate_datasets(input_organs, target_organ):\n",
    "    \"\"\"\n",
    "    Generates datasets for training and testing based on specified input and target organs.\n",
    "    \n",
    "    Args:\n",
    "    - input_organs (list of str): List of organ names to be used as input.\n",
    "    - target_organ (str): Name of the target organ.\n",
    "    \n",
    "    Returns:\n",
    "    - tuple: Contains four numpy arrays - X_train, X_test, y_train, and y_test.\n",
    "    \"\"\"\n",
    "    # Convert the organ names to their respective lists\n",
    "    organ_dict = {\n",
    "        \"liver\": liver_range_list,\n",
    "        \"kidneys\": kidneys_range_list,\n",
    "        \"spleen\": spleen_range_list,\n",
    "        \"bowel\": bowel_range_list\n",
    "    }\n",
    "    \n",
    "    # Create input and target datasets\n",
    "    X = np.hstack([organ_dict[organ] for organ in input_organs])\n",
    "    y = organ_dict[target_organ]\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "# Define the combinations\n",
    "combinations = [\n",
    "    ([\"liver\", \"bowel\"], \"kidneys\"),\n",
    "    ([\"liver\", \"spleen\", \"bowel\"], \"kidneys\"),\n",
    "    ([\"liver\", \"bowel\"], \"spleen\"),\n",
    "    ([\"liver\", \"kidneys\", \"bowel\"], \"spleen\"),\n",
    "    ([\"liver\", \"kidneys\", \"spleen\"], \"bowel\"),  \n",
    "    ([\"liver\", \"kidneys\"], \"bowel\"),  \n",
    "    ([\"liver\"], \"bowel\"),  \n",
    "    ([\"liver\"], \"kidneys\"),\n",
    "    ([\"liver\"], \"spleen\")\n",
    "]\n",
    "\n",
    "# For each combination\n",
    "for input_organs, target_organ in combinations:\n",
    "    X_train, X_test, y_train, y_test = generate_datasets(input_organs, target_organ)\n",
    "    \n",
    "    # Initialize the model\n",
    "    model = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Save the model\n",
    "    model_filename = f\"model_predicting_{target_organ}_using_{'_'.join(input_organs)}.joblib\"\n",
    "    joblib.dump(model, model_filename)\n",
    "    print(f\"Model saved as {model_filename}\")\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f\"Using {input_organs} to predict {target_organ} - Mean Squared Error: {mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73454ae6-0f95-4869-8c7e-7a2da3e2127a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "models_dict = {}\n",
    "\n",
    "# Directory where your models are saved\n",
    "models_directory = os.getcwd()\n",
    "\n",
    "for input_organs, target_organ in combinations:\n",
    "    model_filename = f\"model_predicting_{target_organ}_using_{'_'.join(input_organs)}.joblib\"\n",
    "    model_path = os.path.join(models_directory, model_filename)\n",
    "    \n",
    "    # Load the model and save to the dictionary\n",
    "    model = joblib.load(model_path)\n",
    "    key = (tuple(input_organs), target_organ)\n",
    "    models_dict[key] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63929538-5452-4c72-9b35-5e4d9b73eee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_index(index, available_organs):\n",
    "    \"\"\"\n",
    "    Retrieves data for a given index across specified organs.\n",
    "    \n",
    "    Args:\n",
    "    - index (int): The index for which data is to be extracted.\n",
    "    - available_organs (list of str): List of organ names for which data needs to be retrieved.\n",
    "    \n",
    "    Returns:\n",
    "    - numpy array: Combined data for the given index across the specified organs.\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    \n",
    "    if \"liver\" in available_organs:\n",
    "        data_list.append(original_liver_range_list[index])\n",
    "    if \"kidneys\" in available_organs:\n",
    "        data_list.append(original_kidneys_range_list[index])\n",
    "    if \"spleen\" in available_organs:\n",
    "        data_list.append(original_spleen_range_list[index])\n",
    "    if \"bowel\" in available_organs:\n",
    "        data_list.append(original_bowel_range_list[index])\n",
    "    \n",
    "    # Combine the data as required\n",
    "    combined_data = np.hstack(data_list)\n",
    "    \n",
    "    return combined_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770f6230-8d07-4990-951d-c44d2e4bd0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store predictions\n",
    "predictions = {}\n",
    "\n",
    "# Iterate through the bad_organs_dict\n",
    "for index, bad_organs in bad_organs_dict.items():\n",
    "    # Convert bad_organs to a list of organ names\n",
    "    available_organs = []\n",
    "    for i, organ in enumerate(['liver', 'kidneys', 'spleen', 'bowel']):\n",
    "        if bad_organs[i] == 0:  # If the organ is available\n",
    "            available_organs.append(organ)\n",
    "    \n",
    "    # For each organ, if it's missing, try to predict it using the available organs\n",
    "    for i, organ in enumerate(['liver', 'kidneys', 'spleen', 'bowel']):\n",
    "        if bad_organs[i] == 1:  # If the organ is missing\n",
    "            key = (tuple(available_organs), organ)\n",
    "            model = models_dict.get(key)\n",
    "            if model:\n",
    "                data = get_data_for_index(index, available_organs)\n",
    "                prediction = model.predict([data])\n",
    "                predictions[(index, organ)] = prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2449d29-0421-4614-a4ee-45bcf959f1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming predictions_dict is the dictionary where you've saved the predictions\n",
    "# For example: predictions_dict = {(11, 'kidneys'): array([0.71556257, 0.94957948]), ...}\n",
    "for (index, organ), prediction in predictions.items():\n",
    "    if organ == 'kidneys':\n",
    "        original_kidneys_range_list[index] = prediction\n",
    "    elif organ == 'liver':\n",
    "        original_liver_range_list[index] = prediction\n",
    "    elif organ == 'spleen':\n",
    "        original_spleen_range_list[index] = prediction\n",
    "    elif organ == 'bowel':\n",
    "        original_bowel_range_list[index] = prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd093513-2193-4c34-9d84-53b628c8029f",
   "metadata": {},
   "outputs": [],
   "source": [
    "definite_kidneys_range_list = original_kidneys_range_list.T*series_depth_lengths\n",
    "definite_kidneys_range_list = definite_kidneys_range_list.T\n",
    "\n",
    "definite_liver_range_list = original_liver_range_list.T*series_depth_lengths\n",
    "definite_liver_range_list = definite_liver_range_list.T\n",
    "\n",
    "definite_spleen_range_list = original_spleen_range_list.T*series_depth_lengths\n",
    "definite_spleen_range_list = definite_spleen_range_list.T\n",
    "\n",
    "definite_bowel_range_list = original_bowel_range_list.T*series_depth_lengths\n",
    "definite_bowel_range_list = definite_bowel_range_list.T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a16218-f0d3-4aa6-ad3a-79d4d416adfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_channel(channel):\n",
    "    \"\"\"\n",
    "    Processes a single channel (R, G, or B) of an image.\n",
    "    \n",
    "    Steps:\n",
    "    1. Thresholds the image based on predefined HU values.\n",
    "    2. Performs a median blur for noise reduction.\n",
    "    3. Applies morphological opening operation to further refine the thresholding.\n",
    "    4. Identifies connected components.\n",
    "    5. Keeps only the two largest components and masks the original channel with these components.\n",
    "    \n",
    "    Args:\n",
    "    - channel (numpy.ndarray): A single channel from an RGB image.\n",
    "    \n",
    "    Returns:\n",
    "    - numpy.ndarray: Processed channel.\n",
    "    \"\"\"\n",
    "    # 1. Thresholding\n",
    "    min_HU = 55  # You'll need to adjust these values based on your dataset\n",
    "    max_HU = 250\n",
    "    _, thresh = cv2.threshold(channel, min_HU, max_HU, cv2.THRESH_BINARY)\n",
    "\n",
    "    thresh = cv2.medianBlur(thresh, 5)\n",
    "    # 2. Morphological Operations\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    dilated = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(dilated, 8, cv2.CV_32S)\n",
    "    areas = stats[:,-1]\n",
    "    \n",
    "    # Exclude the background label and get the two largest areas\n",
    "    largest_indices = np.argsort(areas[1:])[-2:] + 1\n",
    "    \n",
    "    connected = np.zeros_like(dilated, np.uint8)\n",
    "    for idx in largest_indices:\n",
    "        connected[labels == idx] = 255\n",
    "    # 5. Masking\n",
    "    result_channel = cv2.bitwise_and(channel, connected)\n",
    "    result_channel[result_channel > 210] = 0\n",
    "\n",
    "    return result_channel\n",
    "\n",
    "def process_image(image_path):\n",
    "    \"\"\"\n",
    "    Processes an RGB image by processing each of its channels separately and then merging them.\n",
    "    \n",
    "    Args:\n",
    "    - image_path (str): Path to the image file.\n",
    "    \n",
    "    Returns:\n",
    "    - numpy.ndarray: Processed RGB image.\n",
    "    \"\"\"\n",
    "    # Read image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Split into RGB channels\n",
    "    r, g, b = cv2.split(image)\n",
    "    \n",
    "    # Process each channel\n",
    "    r_processed = process_channel(r)\n",
    "    g_processed = process_channel(g)\n",
    "    b_processed = process_channel(b)\n",
    "    \n",
    "    # Merge processed channels\n",
    "    processed_image = cv2.merge([r_processed, g_processed, b_processed])\n",
    "\n",
    "    return processed_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d31221-41a4-4913-a37b-67c9ba202686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def collect_jpg_data(base_directory):\n",
    "    \"\"\"\n",
    "    Traverse the directory structure and collect paths to .jpg files.\n",
    "    \n",
    "    Args:\n",
    "    - base_directory (str): Root directory containing subdirectories of .jpg files.\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: Contains .jpg file path, series_id, and image data for each .jpg file.\n",
    "    \"\"\"\n",
    "    # List to collect data\n",
    "    jpg_data = []\n",
    "\n",
    "    # Iterate through all subdirectories in the base directory\n",
    "    for sub_dir in tqdm(os.listdir(base_directory)):\n",
    "        sub_dir_path = os.path.join(base_directory, sub_dir)\n",
    "        \n",
    "        if os.path.isdir(sub_dir_path):\n",
    "            series_id = int(sub_dir)  # Assuming the subdirectory name is the series_id\n",
    "            \n",
    "            # Iterate through all files in the subdirectory\n",
    "            for file_name in os.listdir(sub_dir_path):\n",
    "                # Check if the current file is a .jpg file\n",
    "                if file_name.endswith('.jpg'):\n",
    "                    file_path = os.path.join(sub_dir_path, file_name)\n",
    "\n",
    "                    name = file_name.split('.')[0]\n",
    "                    # Append details to the list\n",
    "                    jpg_data.append({\n",
    "                        'jpg_path': file_path,\n",
    "                        'series_id': series_id,\n",
    "                        'file_name': name\n",
    "                    })\n",
    "\n",
    "    # Convert the list into a DataFrame\n",
    "    jpg_df = pd.DataFrame(jpg_data)\n",
    "    \n",
    "    return jpg_df\n",
    "\n",
    "# Example usage\n",
    "base_directory = 'volume_images'  # Replace with your directory path\n",
    "jpg_df = collect_jpg_data(base_directory)\n",
    "jpg_df=jpg_df.sort_values(by='series_id',axis=0).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15acca4-4b15-40bb-af4b-f88bb49ebd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = 'series_image_split' \n",
    "\n",
    "if not os.path.exists(base_path):\n",
    "    os.makedirs(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903027b4-c27a-4fcf-9a72-bf2cb51deed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_save_images_from_paths(series_id, depth_range, organ, filepaths, filenames, base_path):\n",
    "    \"\"\"\n",
    "    Extracts and saves images based on depth ranges for each organ.\n",
    "    \n",
    "    Args:\n",
    "    - series_id (str): The ID of the series.\n",
    "    - depth_ranges (list of tuples): The depth ranges of the organ in the format [(start1, end1), (start2, end2), ...].\n",
    "    - organ (str): The name of the organ (e.g., \"liver\", \"kidneys\").\n",
    "    - filepaths (list of str): List of paths to the image files.\n",
    "    - base_path (str): Base directory to save the extracted images.\n",
    "    \"\"\"\n",
    "    series_path = os.path.join(base_path, series_id)\n",
    "    organ_path = os.path.join(series_path, organ)\n",
    "    \n",
    "    if not os.path.exists(organ_path):\n",
    "        os.makedirs(organ_path)\n",
    "\n",
    "    start, end = depth_range\n",
    "    if organ == 'bowel' and end > 250:\n",
    "        start = start + 30\n",
    "        \n",
    "    for i in range(len(filepaths)):\n",
    "        filepath = filepaths[i]\n",
    "        filename = filenames[i]\n",
    "        # Extracting the filename without extension            \n",
    "        # Check if the filename is a number and within the specified depth range\n",
    "        if filename.isdigit() and start <= int(filename) <= end:\n",
    "\n",
    "            img = Image.open(filepath)\n",
    "            save_path = os.path.join(organ_path, f\"{filename}.jpg\")\n",
    "            img.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae19987-6475-421a-ba64-5b83562ca9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(len(series_list))):\n",
    "    series_list = np.unique(jpg_df.series_id)\n",
    "    curr_id = series_list[i]\n",
    "    jpg_path_list = np.array(jpg_df[jpg_df.series_id==curr_id].jpg_path)\n",
    "    jpg_name_list = np.array(jpg_df[jpg_df.series_id==curr_id].file_name)\n",
    "    \n",
    "    extract_and_save_images_from_paths(str(curr_id), definite_kidneys_range_list[i], 'kidneys', jpg_path_list, jpg_name_list, base_path)\n",
    "    extract_and_save_images_from_paths(str(curr_id), definite_bowel_range_list[i], 'bowel', jpg_path_list, jpg_name_list, base_path)\n",
    "    extract_and_save_images_from_paths(str(curr_id), definite_liver_range_list[i], 'liver', jpg_path_list, jpg_name_list, base_path)\n",
    "    extract_and_save_images_from_paths(str(curr_id), definite_spleen_range_list[i], 'spleen', jpg_path_list, jpg_name_list, base_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
